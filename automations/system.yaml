- alias: ðŸ“± Sensor low battery notification (ðŸ”‹ < 10%)
  id: bf5935e5-b716-4bfd-8949-71b01b4f484f
  variables:
    # Exclude mobile devices
    exclude:
      - sensor.p20hd_eea_battery_level
      - sensor.sm_g930f_battery_level
      - sensor.pixel_6_pro_battery_level
    sensors: >-
      {% set result = namespace(sensors=[]) %}
      {% for state in states.sensor |
          selectattr('attributes.device_class', '==', 'battery') |
          rejectattr('entity_id', 'in', exclude) %}
        {# Cannot use "selectattr" as a numeric comparison is needed #}
        {% if state.state | int(100) < 10 %}
            {% set result.sensors = result.sensors +
              [state.name ~ ': ' ~ state.state ~ '%'] %}
        {% endif %}
      {% endfor %}
      {{ result.sensors }}
  trigger:
    - platform: time
      at: "10:00:00"
  condition:
    # Only on Saturday if there are battery-levels below 10%
    - condition: template
      value_template: >-
        {{ now().isoweekday() == 6 and sensors | length > 0 }}
  action:
    - service: script.turn_on
      target:
        entity_id: script.persistent_notification
      data:
        variables:
          group: general
          channel: Notification
          targetDevices: my
          title: ðŸ”‹ Low sensor battery
          message: >-
            The following sensors have a battery level below 10%:
            <br><br>â—¾ {{
              sensors | join('<br>â—¾ ')
            -}}
  mode: single
- alias: ðŸ“± Notify on device failure (unavailable/unknown/none-state)
  id: 4c3d9da3-51c8-4881-9df0-8dec257d6d12
  trigger:
    - platform: state
      entity_id: sensor.failed_devices
  condition:
    # Guard against an invalid state in the sensor (as any state change triggers
    # the automation)
    - condition: template
      value_template: >-
        {{ states('sensor.failed_devices') not in ['unknown', 'unavailable'] }}
    # Don't notify if there's no Internet- or Nabu Casa-connectivity (a likely
    # cause of failures). Once the connectivity issue(s) clear, any persistent
    # failures will show up in the next notification...
    - condition: state
      entity_id: binary_sensor.google_dns_ping
      state: "on"
    - condition: state
      entity_id: binary_sensor.remote_ui
      state: "on"
  action:
    - choose:
        # If there are no (more) failures, dismiss the notification
        - conditions:
            - condition: template
              value_template: >-
                {{ states('sensor.failed_devices') | from_json | length == 0 }}
          sequence:
            - service: persistent_notification.dismiss
              data:
                notification_id: device_failure
      default:
        - variables:
            devices: >-
              {{ states('sensor.failed_devices') | from_json }}
        - service: script.turn_on
          target:
            entity_id: script.persistent_notification
          data:
            variables:
              group: general
              channel: Notification
              tag: device_failure
              targetDevices: my
              title: ðŸ’¥ Device failure(s)
              message: >-
                The following device(s) appear to have (partially) failed:<br>
                <br><br>â—¾ {{
                  devices | join('<br>â—¾ ')
                -}}
  mode: restart
# The Recorder's SQLite-database is on a separate NVMe USB-drive that â€“ although
# generally stable â€“ occasionally disconnects. It reconnects right away and the
# filesystem is automatically remounted, but Docker doesn't take very kindly to
# this: All containers using the volume need to be stopped and only then (once
# they're all down) restarted for the volume to become accessible again...
- alias: ðŸ“± | ðŸ’½ Notify on Recorder-component failure
  id: 28b00ed1-a3b0-4d7f-97bc-b1faf3b446d1
  trigger:
    platform: event
    event_type: system_log_event
    event_data:
      level: ERROR
      name: homeassistant.components.recorder
  condition: []
  action:
    # Explicitly block any further runs of this automation while the
    # notification is up (i.e. once a notification is up, no additional
    # notifications are raised)
    - service: script.persistent_notification
      data:
        group: general
        channel: Alert
        targetDevices: my
        criticalNotification: true
        title: ðŸ’½ Recorder-component failure!
        message: >-
          The recorder-component failed with the folllowing error:
          <br><br>
          {{ trigger.event.data.message }}
  mode: single
  max_exceeded: silent
# Occasionally, a race-condition occurs at startup where the deCONZ-integration
# isn't yet up and running when the automations (that depend on devices provided
# by deCONZ) are loaded. This causes all automations that depend on deCONZ
# devices to fail to initialise. A reload of the automations once deCONZ is up
# and running resvoles the issue.
# Below is a canary automation (specifically intended to fail to initialise on
# the race-condition) and a second automation that reloads all automations when
# the canary fails. Set up in this way to prevent having to create an automation
# which triggers (the evaluation of a template condition) on _all_ logged ERRORs
# (as that is the only other way to detect the race-condition).
- alias: ðŸš§ | ðŸ•¹ï¸ Reload automations at startup â€“ canary
  id: 4705ec2c-8003-43dd-b5a0-0fbd0409673e
  trigger:
    # Random/unlikely trigger â€“ doesn't really matter, but tried to pick one
    # that doesn't occur a lot...
    - device_id: 7053d7e589bf4a4496cff59a24b7c83c
      domain: deconz
      platform: device
      type: remote_moved
      subtype: side_6
  condition:
    # Prevent automation from actually executing
    - condition: template
      value_template: >-
        {{ false }}
  action: []
  mode: single
- alias: ðŸš§ | ðŸ•¹ï¸ Reload automations at startup (deCONZ race-condition)
  id: c47ad5f2-8a4b-4d9d-88c0-b375d5c16df9
  trigger:
    - platform: event
      event_type: system_log_event
      event_data:
        level: ERROR
        name: homeassistant.components.automation.reload_automations_at_startup_canary
  condition:
    - condition: template
      value_template: >-
        {{ "'No deconz_event tied to device " in trigger.event.data.message }}
  action:
    # Give deCONZ a bit of time to initialise; repeated failures will simply
    # trigger this automation again...
    - delay: "00:01:00"
    - service: automation.reload
  mode: single
  max_exceeded: silent
- alias: ðŸ“±/ðŸš¨ | âš¡ Notify on prolonged power outage (â° > 10 minutes)
  id: 8ff8c413-b877-41af-bc9d-8e72b1b9bcab
  trigger:
    - platform: state
      entity_id: binary_sensor.power_outage
      to: "on"
      for: "00:10:00"
  condition:
    # If Home Alarm is "Armed away", a different â€“ more immediate â€“ response is
    # issued...
    - condition: not
      conditions:
        - condition: state
          entity_id: alarm_control_panel.home_alarm
          state: armed_away
  action:
    - service: script.turn_on
      target:
        entity_id: script.sms_notification
      data:
        variables:
          targetDevices: my
          message: >-
            âš¡ There appears to be a power outage!
            {% if states.sensor.ups_status is defined -%}
              \nHome Assistant has been running on back-up battery power for {{
                  relative_time(states.sensor.ups_status.last_changed)
                }} and has {{
                  states('sensor.ups_battery_runtime_minutes')
                }} minutes of runtime remaining...
            {%- endif -%}
    # If someone is home, also sound the alarm. The ZigBee controller is
    # connected to the UPS; the sirens have backup batteries so most likely
    # this'll work... ðŸ¤ž
    - condition: state
      entity_id: group.family
      state: home
    - service: script.turn_on
      target:
        entity_id: script.sirens
      data:
        # Short pulses for 2 minutes; just to get people's attention
        variables:
          mode: pulse
          ontime: 120
  mode: single
- alias: ðŸ“± | ðŸ“¡ Notify on loss of (Internet-)connectivity
  id: aef11607-656e-41cc-8eb8-f2f18959ebeb
  trigger:
    - platform: state
      entity_id: binary_sensor.google_dns_ping
      from: "on"
      to: "off"
      # Ping updates once per minute â€“ trigger when two consecutive pings fail
      # (with a bit of margin to account for longer ping times).
      for: "00:02:30"
    - platform: state
      entity_id: binary_sensor.remote_ui
      from: "on"
      to: "off"
      # Remote UI appears to drop offline for a couple minutes every now and
      # then, so this is a bit less trigger happy.
      for: "00:10:00"
  action:
    - service: script.sms_notification
      data:
        targetDevices: my
        message: >-
          {%- if trigger.entity_id == 'binary_sensor.remote_ui' -%}
            ðŸ“¡ Home Assistant lost connectivity!
            \nHome Assistant appears to have lost connection with Nabu Casa.
          {%-
            elif trigger.entity_id == 'binary_sensor.google_dns_ping'
          -%}
            ðŸ“¡ Home Assistant lost Internet-connectivity!
            \nHome Assistant is unable to ping Google's Public DNS.
          {%- endif %} To inspect the state of the house:
          \n\nâœ‰ï¸ #secret# status [camera]
          \n\nTo check and control the Home Alarm:
          \n\nâœ‰ï¸ #secret# alarm [arm|disarm|silence]
    # Wait for connectivity to be restored â€“ simultaneously blocks subsequent
    # connectivity triggers from resending the SMS
    - wait_for_trigger:
        - platform: template
          value_template: >-
            {{ states(trigger.entity_id) == 'on' }}
          for: "00:02:30"
      timeout: "12:00:00"
      continue_on_timeout: false
    - service: script.sms_notification
      data:
        targetDevices: my
        message: >-
          ðŸ“¡ Home Assistant connectivity restored
  mode: single
  max_exceeded: silent
# Stop Home Assistant (mainly to prevent database corruption) if a power failure
# appears imminent
- alias: ðŸš§ | ðŸ”‹ Stop Home Assistant (UPS ðŸ”‹ < 10%)
  id: e7dcf99d-a13d-43ed-a828-d19335c94787
  trigger:
    - platform: numeric_state
      entity_id: sensor.ups_battery_charge
      below: 10
  condition:
    # This intentionally does _not_ use "binary_sensor.power_outage" as the
    # below truly relies on the UPS and acts independent from the generalised
    # concept of a power outage...
    - condition: state
      entity_id: sensor.ups_status
      state: On Battery Battery Discharging
  action:
    # Block on sending the SMS notification (to prevent shutting down Home
    # Assistant before the message is send)
    - service: script.sms_notification
      data:
        targetDevices: my
        message: >-
          ðŸ”‹ UPS low power!
          \nUPS battery level below 10%; power failure appears imminent â€“
          stopping Home Assistant...
    - service: system_log.write
      data:
        level: critical
        message: >-
          UPS battery level below 10%; power failure appears imminent â€“
          stopping Home Assistant...
    - service: homeassistant.stop
  mode: single
