- alias: 📱 | 🔋  Notify on devices with low battery (🔋 < 20%)
  id: bf5935e5-b716-4bfd-8949-71b01b4f484f
  variables:
    devices: >-
      {{ states('sensor.low_battery_devices') | from_json }}
  trigger:
    # There's no need for realtime notifications; once daily suffices
    - platform: time
      at: "19:00:00"
  condition:
    - condition: template
      value_template: >-
        {{ devices | length > 0 }}
  action:
    - service: script.turn_on
      target:
        entity_id: script.persistent_notification
      data:
        variables:
          group: general
          channel: Notification
          targetDevices: my
          title: 🔋 Device(s) with low battery
          message: >-
            The following devices have a battery level below 20%:
            <br><br>◾ {{
              devices | join('<br>◾ ')
            -}}
    - service: script.turn_on
      target:
        entity_id: script.tts_queue
      data:
        variables:
          expiry: "06:00:00"
          message: >-
            {% if devices | length > 1 %}
              There are {{ devices | length }} devices with a battery level
              below 20% in the house...
            {% else %}
              {{ devices | first }} has a battery level below 20%...
            {% endif %}
  mode: single
- alias: 📱 | 💥 Notify on device failure (unavailable/unknown-state)
  id: 4c3d9da3-51c8-4881-9df0-8dec257d6d12
  trigger:
    # The sensor updates every 5-minutes — holding the state for 6-minutes
    # allows transient and short-lived failures (ones that appear for only a
    # single 5-minute interval) to be filtered out. At the cost of making the
    # reporting somewhat less accurate and responsive it filters out a lot of
    # noise...
    - platform: state
      entity_id: sensor.failed_devices
      to: ~
      for: "00:06:00"
  condition:
    # If the active set of failed devices (i.e., the set currently up in the
    # notification) is identical to the incoming set, don't send a new
    # notification. This (combined with the trigger delay) ensures transient
    # failures are not notified upon.
    # This limits unnecessary use of notifications, but mainly serves to prevent
    # a situation where a non-critical failure notification is up (but dismissed
    # from the phone) and a transient failure occurs. In this case the
    # resolving of the transient failure would cause the original (dismissed)
    # notification to reappear on the phone...
    - condition: template
      value_template: >-
        {{
          states('input_text.failed_devices_active') !=
            states('sensor.failed_devices')
        }}
    # Don't notify if there's no Internet- or Nabu Casa-connectivity (a likely
    # cause of failures). Once the connectivity issue(s) clear, any persistent
    # failures will show up in the next notification...
    - condition: state
      entity_id: binary_sensor.google_dns_ping
      state: "on"
    - condition: state
      entity_id: binary_sensor.remote_ui
      state: "on"
  action:
    - service: input_text.set_value
      target:
        entity_id: input_text.failed_devices_active
      data:
        value: >-
          {{ states('sensor.failed_devices') }}
    - choose:
        # If there are no (more) failures, dismiss the notification
        - conditions:
            - condition: template
              value_template: >-
                {{ states('sensor.failed_devices') | from_json | length == 0 }}
          sequence:
            - service: persistent_notification.dismiss
              data:
                notification_id: device_failure
      default:
        - variables:
            devices: >-
              {{ states('sensor.failed_devices') | from_json }}
        - service: script.turn_on
          target:
            entity_id: script.persistent_notification
          data:
            variables:
              group: general
              channel: Notification
              tag: device_failure
              targetDevices: my
              title: >-
                💥 {{ devices | length }} Device {{
                  'failures' if devices | length > 1 else 'failure'
                -}}
              message: >-
                The following {{
                  'devices appear' if devices | length > 1 else 'device appears'
                }} to have (partially) failed:
                <br><br>◾ {{
                  devices | join('<br>◾ ')
                }}
  mode: restart
- alias: >-
    📱 | 💧 Notify on potential Watermeter failure (no flow ⏰ > 24-hours)
  id: b62ec927-5bef-433c-9233-af5bcc06d140
  trigger:
    - platform: numeric_state
      entity_id: sensor.flow_watermeter
      below: 0.1
      for: "24:00:00"
  condition:
    # Unlikely to happen, unless we're on vacation
    - condition: state
      entity_id: input_boolean.alarm_vacation_mode
      state: "off"
  action:
    - service: script.turn_on
      target:
        entity_id: script.persistent_notification
      data:
        variables:
          group: general
          channel: Notification
          targetDevices: my
          title: 💧 Potential Watermeter failure
          message: >-
            Watermeter recorded zero water flow over the past 24-hours; its
            sensor has most likely been unseated...
  mode: single
- alias: 📱 | 🔊 Notify if "TTS announce"-script appears stuck
  id: 51400b7c-20e9-49bf-91d1-51e465189e68
  trigger:
    - platform: state
      entity_id: script.tts_announce
      from: "off"
      to: "on"
      # Highly unlikely for any (set of) announcement(s) to run for more than
      # 5-minutes...
      for: "00:05:00"
  condition: []
  action:
    # Explicitly block any further runs of this automation while the
    # notification is up
    - service: script.persistent_notification
      data:
        group: general
        channel: Alert
        importance: high
        targetDevices: my
        title: 💥 The "TTS announce"-script appears stuck
        message: >-
          It has been in the "on"-state for {{
            (trigger.for.seconds / 60) | round
          }}-minutes; probably one of the MPD-instances has hung...
  mode: single
  max_exceeded: silent
# Occasionally, a race-condition occurs at startup where the deCONZ-integration
# isn't yet up and running when the automations (that depend on devices provided
# by deCONZ) are loaded. This causes all automations that depend on deCONZ
# devices to fail to initialise. A reload of the automations once deCONZ is up
# and running resvoles the issue.
# Below is a canary automation (specifically intended to fail to initialise on
# the race-condition) and a second automation that reloads all automations when
# the canary fails. Set up in this way to prevent having to create an automation
# which triggers (the evaluation of a template condition) on _all_ logged ERRORs
# (as that is the only other way to detect the race-condition).
- alias: 🚧 | 🕹️ Reload automations at startup – canary
  id: 4705ec2c-8003-43dd-b5a0-0fbd0409673e
  trigger:
    # Random/unlikely trigger – doesn't really matter, but tried to pick one
    # that doesn't occur a lot...
    - device_id: 7053d7e589bf4a4496cff59a24b7c83c
      domain: deconz
      platform: device
      type: remote_moved
      subtype: side_6
  condition:
    # Prevent automation from actually executing
    - condition: template
      value_template: >-
        {{ false }}
  action: []
  mode: single
- alias: 🚧 | 🕹️ Reload automations at startup (deCONZ race-condition)
  id: c47ad5f2-8a4b-4d9d-88c0-b375d5c16df9
  trigger:
    - platform: event
      event_type: system_log_event
      event_data:
        level: ERROR
        name: homeassistant.components.automation.reload_automations_at_startup_canary
  condition:
    - condition: template
      value_template: >-
        {{
          trigger.event.data.message is search(
            "No deconz_event tied to device ")
        }}
  action:
    # Give deCONZ a bit of time to initialise; repeated failures will simply
    # trigger this automation again...
    - delay: "00:01:00"
    - service: system_log.write
      data:
        level: warning
        message: >-
          deCONZ canary triggered; reloading automations...
    - service: automation.reload
  mode: single
  max_exceeded: silent
- alias: 📱/🚨 | ⚡ Notify on prolonged power outage (⏰ > 10 minutes)
  id: 8ff8c413-b877-41af-bc9d-8e72b1b9bcab
  trigger:
    - platform: state
      entity_id: binary_sensor.power_outage
      to: "on"
      for: "00:10:00"
  condition:
    # If Home Alarm is "Armed away", a different – more immediate – response is
    # issued...
    - condition: not
      conditions:
        - condition: state
          entity_id: alarm_control_panel.home_alarm
          state: armed_away
  action:
    - service: script.turn_on
      target:
        entity_id: script.sms_notification
      data:
        variables:
          targetDevices: my
          message: >-
            ⚡ There appears to be a power outage!
            {% if states.sensor.ups_status is defined -%}
              \nHome Assistant has been running on back-up battery power for {{
                  relative_time(states.sensor.ups_status.last_changed)
                }} and has {{
                  states('sensor.ups_battery_runtime_minutes')
                }} minutes of runtime remaining...
            {% endif %}
    # If someone is home, also sound the alarm. The ZigBee controller is
    # connected to the UPS; the sirens have backup batteries so most likely
    # this'll work... 🤞
    - condition: state
      entity_id: group.family
      state: home
    - service: script.turn_on
      target:
        entity_id: script.sirens
      data:
        # Short pulses for 2 minutes; just to get people's attention
        variables:
          mode: pulse
          ontime: 120
  mode: single
- alias: 📱 | 📡 Notify on loss of (Internet-)connectivity
  id: aef11607-656e-41cc-8eb8-f2f18959ebeb
  trigger:
    - platform: state
      entity_id: binary_sensor.google_dns_ping
      from: "on"
      to: "off"
      # Ping updates once per minute – trigger when two consecutive pings fail
      # (with a bit of margin to account for longer ping times).
      for: "00:02:30"
    - platform: state
      entity_id: binary_sensor.remote_ui
      from: "on"
      to: "off"
      # Remote UI appears to drop offline for a couple minutes every now and
      # then, so this is a bit less trigger happy.
      for: "00:10:00"
  action:
    - service: script.sms_notification
      data:
        targetDevices: my
        message: >-
          {% if trigger.entity_id == 'binary_sensor.remote_ui' %}
            📡 Home Assistant lost connectivity!\n
            Home Assistant appears to have lost connection with Nabu Casa.
          {%
            elif trigger.entity_id == 'binary_sensor.google_dns_ping'
          %}
            📡 Home Assistant lost Internet-connectivity!\n
            Home Assistant is unable to ping Google's Public DNS.
          {% endif %} To inspect the state of the house:
          \n\n✉️ #secret# status [camera]
          \n\nTo check and control the Home Alarm:
          \n\n✉️ #secret# alarm [arm|disarm|silence]
    # Wait for connectivity to be restored – simultaneously blocks subsequent
    # connectivity triggers from resending the SMS
    - wait_for_trigger:
        - platform: template
          value_template: >-
            {{ states(trigger.entity_id) == 'on' }}
          for: "00:02:30"
      timeout: "12:00:00"
      continue_on_timeout: false
    - service: script.sms_notification
      data:
        targetDevices: my
        message: >-
          📡 Home Assistant connectivity restored
  mode: single
  max_exceeded: silent
# Stop Home Assistant (mainly to prevent database corruption) if a power failure
# appears imminent
- alias: 🚧 | 🔋 Stop Home Assistant (UPS 🔋 < 15%)
  id: e7dcf99d-a13d-43ed-a828-d19335c94787
  trigger:
    - platform: numeric_state
      entity_id: sensor.ups_battery_charge
      below: 15
  condition:
    # This intentionally does _not_ use "binary_sensor.power_outage" as the
    # below truly relies on the UPS and acts independent from the generalised
    # concept of a power outage...
    - condition: state
      entity_id: sensor.ups_status
      state: On Battery Battery Discharging
  action:
    - service: script.turn_on
      target:
        entity_id: script.sms_notification
      data:
        variables:
          targetDevices: my
          message: >-
            🔋 UPS low power!\n
            UPS battery level below 10%; power failure appears imminent –
            stopping Home Assistant...
    - service: system_log.write
      data:
        level: critical
        message: >-
          UPS battery level below 10%; power failure appears imminent – stopping
          Home Assistant...
    # Delay for 30 seconds – give the SMS a bit of time to get out, but don't
    # block as we not want to prevent a shutdown altogether...
    - delay: "00:00:30"
    - service: homeassistant.stop
  mode: single
