# The Recorder's SQLite-database is on a separate NVMe USB-drive that – although
# generally stable – occasionally disconnects. It reconnects right away and the
# filesystem is automatically remounted, but Docker doesn't take very kindly to
# this: All containers using the volume need to be restarted for the volume to
# become accessible again...
# I've tried using udev rules to cope with this, but that turned out to be
# difficult to get right (and/or properly test). The below (blunt; "if the only
# tool you have is a hammer, every problem looks like a nail"-type of solution)
# appears to work better.
# It is anyway temporary of nature: I'm planning to change the machine running
# Home Assistant at the start of 2023. The problem is specific to the
# combination of device (RPi4), USB enclosure (RTL9210), and OS (Ubuntu 20.04)
# in-use — a hardware-wise identical setup running Ubuntu 22.04 doesn't suffer
# from any of these issues (it could potentially be the RTL9210 firmware, but
# the version of smartmontools on Ubuntu 20.04 is too old to check that 🤐).

# Somewhat superfluous failure-notification. Left in place with a 6-minute delay
# which effectively makes this the backstop notification (i.e., it is only send
# if the container restart fails).
- alias: 📱 | 💽 Notify on Recorder-component failure
  id: 28b00ed1-a3b0-4d7f-97bc-b1faf3b446d1
  trigger:
    platform: event
    event_type: system_log_event
    event_data:
      level: ERROR
      name: homeassistant.components.recorder.core
  condition: []
  action:
    - delay: "00:06:00"
    - service: script.turn_on
      target:
        entity_id: script.sms_notification
      data:
        variables:
          targetDevices: my
          message: >-
            💽 Recorder-component failure!\n
            The recorder-component failed with the folllowing error:
            \n\n
            {{ trigger.event.data.message }}
    # Explicitly block any further runs of this automation while the
    # notification is up (i.e. once a notification is up, no additional
    # notifications are raised)
    - service: script.persistent_notification
      data:
        group: general
        channel: Alert
        targetDevices: my
        criticalNotification: true
        title: 💽 Recorder-component failure!
        message: >-
          The recorder-component failed with the folllowing error:
          <br><br>
          {{ trigger.event.data.message }}
  mode: single
  max_exceeded: silent
- alias: 💥 | 💽 Restart container on Recorder-component failure
  id: 50e8e275-db77-4e50-9b77-604d5ed221da
  # Triggers on three errors that clearly indicate some kind of disk/IO problem
  # with the database file. Triggering on those (and not the more abundant)
  # transactional errors that ensue after the failure to prevent triggering in
  # case of non-hardware related issues. There are three triggers defined to
  # increase reliability.
  trigger:
    - platform: event
      event_type: system_log_event
      event_data:
        level: ERROR
        name: homeassistant.components.recorder.core
    - platform: event
      event_type: system_log_event
      event_data:
        level: ERROR
        name: homeassistant.components.recorder.util
  condition:
    - condition: template
      value_template: >-
        {% if trigger.event.data.name ==
          "homeassistant.components.recorder.core" %}
          {{
            trigger.event.data.message is search(
              "^Error in database connectivity during commit: Error executing "
              ~ "query: (.*) disk I/O error") or
            trigger.event.data.message is search(
              "^Unrecoverable sqlite3 database corruption detected: (.*) "
              ~ "database disk image is malformed")
          }}
        {% elif trigger.event.data.name ==
          "homeassistant.components.recorder.util" %}
          {{
            trigger.event.data.message is search(
              "The system will rename the corrupt database file")
          }}
        {% endif %}
  action:
    # Request the Home Assistant-container to be restarted
    - service: shell_command.restart_container
    - service: script.turn_on
      target:
        entity_id: script.persistent_notification
      data:
        variables:
          group: general
          channel: Alert
          tag: container_restart
          targetDevices: my
          criticalNotification: true
          title: 💥 Requested Home Assistant-container restart!
          message: >-
            It appears the NVMe-drive disconnected — requested a restart of the
            Home Assistant-container!<br>
            The restart should occur somewhere within the next 5-minutes;
            please stand-by...
    # Block further runs of this automation (warnings enabled). The restart is
    # not instantaneous — a script outside the container checks for an active
    # request every 5-minutes
    - delay: "00:10:00"
  mode: single
  max_exceeded: warning
- alias: 📱 Notify on container restart
  id: 9f3418fe-874f-4d68-9ed1-48224450f03a
  trigger:
    - platform: homeassistant
      event: start
  condition:
    # The external script tracks container restart timestamp in a log-file
    # (mapped to "sensor.container_restart"). If Home Assistant starts within
    # 5-minutes of a container restart, assume that was the reason.
    - condition: template
      value_template: >-
        {{
          states('sensor.container_restart') | as_datetime
            >= now() - timedelta(minutes = 5)
        }}
  action:
    # Replace the previously raised failure notification with a restart
    # notification instead
    - service: script.persistent_notification
      data:
        group: general
        channel: Alert
        tag: container_restart
        targetDevices: my
        criticalNotification: true
        title: 💽 Home Assistant-container restarted due to NVMe-drive failure!
        message: >-
          A failure of the NVMe-drive lead to a Home Assistant-container
          restart — please manually ensure all is well again...
  mode: single
  max_exceeded: silent
